# 🤟 ASL Learning Buddy

**ASL Learning Buddy** is a web application designed to help users learn American Sign Language in an interactive and user-friendly way. This project was built as part of a hackathon challenge to encourage inclusive and accessible learning through technology.

---

## 🌐 Live Demo

🔗 [Click here to try the app](https://asl-learning-buddy.vercel.app/)

---

## 💻 Tech Stack

| Frontend       | Tool/Library       |
|----------------|--------------------|
| Framework      | React (with Vite)  |
| Language       | TypeScript         |
| Styling        | Tailwind CSS       |
| Model          | Hugging Face       |
| Package Manager| npm / yarn         |
| Deployment     | Vercel / GitHub Pages |

---
## 🚀 Inspiration

Communication is a fundamental human right — but millions in the deaf and hard-of-hearing community still face daily obstacles in being understood. While American Sign Language (ASL) is a powerful bridge, it remains inaccessible to most people unfamiliar with it.

I built **ASL Learning Buddy** to change that.

My goal was simple: make ASL approachable through technology. Not just as a learning tool, but as a platform that empowers real-time interaction using sign language — turning curiosity into capability.

---

## 💡 What It Does

**ASL Learning Buddy** is a web-based platform designed to:

- 🧠 **Teach ASL signs** through clean, interactive modules
- 📷 **Recognize hand signs in real-time** using webcam input
- 🔁 **Translate ASL to text** on the fly
- 🔊 **Convert text to speech**, enabling two-way communication

The platform isn't just for learners — it's a practical bridge between hearing and non-hearing communities.

---

## 🧱 Current Challenges

This is just the beginning — and like any good version 1.0, it’s a working prototype with clear room for growth:

- ⚙️ **Model Accuracy**: The current Hugging Face model isn’t hitting the reliability I expect. Different lighting, hand sizes, and speeds impact the predictions. I'm already working on a custom TensorFlow model paired with MediaPipe for better precision.
- 🕸️ **UI Polish**: While functional, the UI needs more finesse. I plan to add smoother transitions, better visual feedback, and overall aesthetic polish.
- 🧪 **Edge Cases**: Fast hand movements or partially-visible signs confuse the model — something I’ll address in the custom build.

---

## 🏆 Achievements So Far

- Developed a **fully functional ASL platform** from scratch — design, code, deploy
- Integrated **live webcam input** with AI-powered sign detection
- Enabled **bi-directional communication**: from signs to text to speech
- Got valuable feedback from early testers, including members of the deaf and hard-of-hearing community
- Made it **accessible for free** on the web — no downloads, no barriers

---

## 📚 What I Learned

- How to work with and fine-tune AI models in-browser using **TensorFlow.js**
- The balance between **technical complexity** and **accessibility**
- Designing with empathy — making every click and interaction count for all users
- That even an early prototype, if built with intent, can spark genuine impact

---

## 🔮 What’s Next for ASL Learning Buddy

This version is just a prototype — a glimpse of what’s coming.

Here’s what I’m building next:

- ✋ A **custom-trained sign recognition model** using TensorFlow + MediaPipe
- 📱 A mobile-friendly version for on-the-go use
- 🧩 **Gamified learning paths** and achievements
- 🗣️ **Voice-to-sign translation** — flipping the interaction the other way
- 🤝 Collaborating with educators and accessibility advocates to refine the experience

This is more than a tool — it’s a mission. One I’m just getting started on.

---

## 🌍 Final Thought

Technology should be a bridge, not a barrier. With ASL Learning Buddy, I’m building a world where learning to communicate is easy, inclusive, and empowering for everyone.




This project was created as part of AI Agent beginners Hackathon, focused on accessible learning tools and inclusive tech solutions.

Created by Varun Singh



